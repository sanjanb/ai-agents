# ğŸ¤– AI Agents â€” Learn & Build

[![Website](https://img.shields.io/badge/Website-Live-brightgreen)](http://localhost:8000)
[![Documentation](https://img.shields.io/badge/Docs-MkDocs-blue)](http://localhost:8000)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)

> **Comprehensive educational resource for designing, building, and deploying AI agents using Large Language Models (LLMs), retrieval-augmented generation (RAG), and cutting-edge fine-tuning techniques.**

## ğŸŒŸ Overview

This project provides a complete learning pathway from foundational LLM concepts to advanced agent implementations, featuring:

- **ğŸ“š 6 Comprehensive Chapters** covering theory and practice
- **ğŸ› ï¸ Hands-On Examples** with runnable code and implementations
- **ğŸ”§ Production-Ready Tools** including evaluation harnesses and tracing utilities
- **âš¡ Efficient Training** techniques like LoRA, QLoRA, and 1-bit LLMs
- **ğŸš€ Deployment Strategies** from local development to cloud production

## ğŸ“– Table of Contents

### Core Chapters

1. **[Foundational LLMs & Text Generation](docs/agents/foundational-llms.md)**

   - LLM architecture and capabilities
   - Text generation techniques and best practices
   - Model selection and evaluation

2. **[Embeddings & Vector Stores](docs/agents/embeddings-vector-stores.md)**

   - Vector representations and similarity search
   - Database integration and indexing strategies
   - Semantic search implementation

3. **[Generative Agents](docs/agents/generative-agents.md)**

   - Agent architectures and reasoning frameworks
   - Tool integration and function calling
   - Memory systems and planning strategies
   - **ğŸ¯ Practical Examples**: Function calling, LangGraph agents, RAG memory

4. **[Domain-Specific LLMs](docs/agents/domain-specific-llms.md)**

   - Adaptation strategies and use cases
   - Data curation and quality management
   - Grounding techniques and external knowledge integration
   - **ğŸ¯ Practical Examples**: Fine-tuning workflows, search grounding

5. **[Fine-Tuning LLMs](docs/agents/fine-tuning-llms.md)**

   - Quantization techniques (4-bit, 8-bit, 1-bit)
   - Parameter-efficient fine-tuning (LoRA, QLoRA)
   - Advanced optimization and deployment
   - **ğŸ¯ Practical Examples**: LoRA implementation, evaluation harness

6. **[Getting Started](docs/agents/getting-started.md)**
   - Environment setup and dependencies
   - Quick start guides and tutorials

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+**
- **Git**
- **Virtual Environment** (recommended)

### Installation & Setup

```bash
# Clone the repository
git clone https://github.com/sanjanb/ai-agents.git
cd ai-agents

# Create and activate virtual environment
python -m venv .venv

# On Windows
.\.venv\Scripts\activate

# On macOS/Linux
source .venv/bin/activate

# Install documentation dependencies
pip install mkdocs mkdocs-material

# Install example dependencies
pip install -r examples/agents/requirements.txt
pip install -r examples/llms/requirements.txt
```

### Run the Documentation Website

```bash
# Start the development server
mkdocs serve

# Open in browser
# Navigate to http://localhost:8000
```

### Try the Examples

#### ğŸ¤– Agent Examples

```bash
# Navigate to examples directory
cd examples/agents

# Run Gemini function calling demo
python gemini_function_calling.py

# Run LangGraph ReAct agent
python langgraph_react_agent.py

# Run RAG memory demonstration
python rag_memory_agent.py

# Run evaluation harness
cd ../../scripts
python eval_rag.py
```

#### ğŸ”§ Fine-Tuning Examples

```bash
# Navigate to LLM examples
cd examples/llms

# Run LoRA fine-tuning
python lora_finetune_news.py --epochs 1 --sample_size 1000

# Evaluate model performance
python eval_domain_classification.py --sample_size 500

# Test search grounding workflow
python search_grounding_stub.py
```

## ğŸ—ï¸ Project Structure

```
ai-agents/
â”œâ”€â”€ ğŸ“ docs/                           # Documentation source
â”‚   â”œâ”€â”€ agents/                        # Chapter content
â”‚   â”‚   â”œâ”€â”€ foundational-llms.md
â”‚   â”‚   â”œâ”€â”€ embeddings-vector-stores.md
â”‚   â”‚   â”œâ”€â”€ generative-agents.md
â”‚   â”‚   â”œâ”€â”€ domain-specific-llms.md
â”‚   â”‚   â”œâ”€â”€ fine-tuning-llms.md
â”‚   â”‚   â””â”€â”€ getting-started.md
â”‚   â””â”€â”€ assets/                        # Images and resources
â”œâ”€â”€ ğŸ“ examples/                       # Runnable code examples
â”‚   â”œâ”€â”€ agents/                        # Agent implementations
â”‚   â”‚   â”œâ”€â”€ gemini_function_calling.py
â”‚   â”‚   â”œâ”€â”€ langgraph_react_agent.py
â”‚   â”‚   â”œâ”€â”€ rag_memory_agent.py
â”‚   â”‚   â”œâ”€â”€ tracing_utils.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ llms/                          # Fine-tuning examples
â”‚       â”œâ”€â”€ lora_finetune_news.py
â”‚       â”œâ”€â”€ eval_domain_classification.py
â”‚       â”œâ”€â”€ search_grounding_stub.py
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ README.md
â”œâ”€â”€ ğŸ“ scripts/                        # Evaluation and utilities
â”‚   â””â”€â”€ eval_rag.py
â”œâ”€â”€ ğŸ“ _layouts/                       # Website templates
â”œâ”€â”€ ğŸ“ assets/                         # Stylesheets and resources
â”œâ”€â”€ ğŸ“„ mkdocs.yml                      # Documentation configuration
â”œâ”€â”€ ğŸ“„ _config.yml                     # Jekyll configuration
â”œâ”€â”€ ğŸ“„ Gemfile                         # Ruby dependencies
â””â”€â”€ ğŸ“„ README.md                       # This file
```

## ğŸ”¬ Features & Capabilities

### ğŸ§  Agent Intelligence

- **Multi-Modal Reasoning**: Text, search, and tool integration
- **Memory Systems**: Short-term and long-term memory management
- **Planning & Reflection**: Strategic decision-making capabilities
- **Tool Integration**: External API and database connectivity

### âš¡ Performance Optimization

- **Quantization**: 4-bit, 8-bit, and 1-bit model compression
- **Parameter-Efficient Training**: LoRA, QLoRA, and adapter techniques
- **Memory Management**: Gradient checkpointing and CPU offloading
- **Distributed Training**: Multi-GPU and cloud deployment strategies

### ğŸ“Š Evaluation & Monitoring

- **Precision@k and MRR**: Information retrieval metrics
- **OpenTelemetry Integration**: Performance tracing and monitoring
- **A/B Testing Framework**: Model comparison and validation
- **Cost Analysis**: Training and inference expense tracking

### ğŸŒ Production Deployment

- **FastAPI Integration**: REST API endpoints for agents
- **Container Support**: Docker deployment configurations
- **Cloud Integration**: Azure, AWS, and GCP compatibility
- **Scaling Strategies**: Load balancing and auto-scaling

## ğŸ¯ Use Cases & Applications

### ğŸ“ˆ Business Intelligence

- **Document Analysis**: Contract review and compliance checking
- **Customer Support**: Intelligent chatbots and ticket routing
- **Market Research**: Trend analysis and competitive intelligence
- **Financial Analytics**: Risk assessment and portfolio management

### ğŸ”¬ Research & Development

- **Literature Review**: Paper summarization and knowledge extraction
- **Hypothesis Generation**: Research question formulation
- **Data Analysis**: Statistical interpretation and visualization
- **Experiment Design**: Methodology development and validation

### ğŸ“ Education & Training

- **Personalized Tutoring**: Adaptive learning systems
- **Content Generation**: Course material and assessment creation
- **Knowledge Assessment**: Automated grading and feedback
- **Skill Development**: Professional training and certification

## ğŸ“Š Performance Benchmarks

### Memory Efficiency Comparison

| Method           | Memory Usage | Training Speed | Accuracy Drop | Use Case            |
| ---------------- | ------------ | -------------- | ------------- | ------------------- |
| Full Fine-tuning | 84GB         | 100%           | 0%            | Maximum accuracy    |
| LoRA             | 14GB         | 160%           | <2%           | Balanced efficiency |
| QLoRA            | 3.6GB        | 155%           | <3%           | Consumer hardware   |
| 1-bit LLMs       | 2.1GB        | 250%           | <5%           | Edge deployment     |

### Agent Performance Metrics

- **Response Latency**: 200-500ms for simple queries
- **Retrieval Accuracy**: Precision@10 > 0.85 on domain datasets
- **Function Calling Success**: >95% accuracy on structured tasks
- **Memory Efficiency**: 16x reduction with minimal quality loss

## ğŸ› ï¸ Development & Contribution

### Development Setup

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
pytest tests/

# Format code
black examples/ scripts/
flake8 examples/ scripts/

# Build documentation
mkdocs build
```

### Contributing Guidelines

1. **Fork the Repository**: Create your own copy for development
2. **Create Feature Branch**: `git checkout -b feature/amazing-feature`
3. **Commit Changes**: `git commit -m 'Add amazing feature'`
4. **Push to Branch**: `git push origin feature/amazing-feature`
5. **Open Pull Request**: Submit your contribution for review

### Code Standards

- **Python Style**: Follow PEP 8 guidelines
- **Documentation**: Include docstrings for all functions
- **Testing**: Add tests for new functionality
- **Examples**: Provide working code demonstrations

## ğŸ”— Resources & References

### ğŸ“š Essential Papers

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Transformer architecture
- [LoRA: Low-Rank Adaptation](https://arxiv.org/abs/2106.09685) - Parameter-efficient fine-tuning
- [QLoRA: Efficient Finetuning](https://arxiv.org/abs/2305.14314) - Quantized fine-tuning
- [BitNet: Scaling 1-bit Transformers](https://arxiv.org/abs/2310.11453) - Ultra-efficient models

### ğŸŒ External Tools & Libraries

- **[Hugging Face Transformers](https://huggingface.co/transformers/)**: Model library and APIs
- **[LangChain](https://langchain.readthedocs.io/)**: Agent framework and tools
- **[FAISS](https://github.com/facebookresearch/faiss)**: Vector similarity search
- **[OpenTelemetry](https://opentelemetry.io/)**: Observability and tracing

### ğŸ“ Learning Paths

- **Beginner**: Start with Foundational LLMs â†’ Embeddings â†’ Getting Started examples
- **Intermediate**: Generative Agents â†’ Domain-Specific adaptation â†’ Fine-tuning basics
- **Advanced**: 1-bit models â†’ Production deployment â†’ Custom agent architectures

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

Special thanks to the open-source community and researchers whose work makes this educational resource possible:

- **Hugging Face Team** for model hosting and tools
- **Meta AI** for Llama model series and research
- **Google Research** for Transformer architecture and Gemini APIs
- **Microsoft** for QLoRA and quantization research
- **OpenAI** for advancing LLM capabilities and best practices

## ğŸ“§ Support & Contact

- **Issues**: [GitHub Issues](https://github.com/sanjanb/ai-agents/issues)
- **Discussions**: [GitHub Discussions](https://github.com/sanjanb/ai-agents/discussions)
- **Documentation**: [Live Website](http://localhost:8000)
- **Email**: Contact repository maintainers for collaboration

---

**ğŸš€ Ready to build intelligent agents? Start with our [Getting Started Guide](docs/agents/getting-started.md) and explore the examples!**
